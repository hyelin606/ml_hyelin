{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "172657cc-bef1-40f9-99b8-531fe55a2685",
   "metadata": {},
   "source": [
    "## 라이브러리 설치\n",
    "- openai 패키지를 설치한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78ca2012-0643-40ba-a5d6-3836dcdfe9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.13.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\imhye\\anaconda3\\envs\\ml_hyelin\\lib\\site-packages (from openai) (4.2.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\imhye\\anaconda3\\envs\\ml_hyelin\\lib\\site-packages (from openai) (0.26.0)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.6.3-py3-none-any.whl.metadata (84 kB)\n",
      "     ---------------------------------------- 0.0/84.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 84.4/84.4 kB 4.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sniffio in c:\\users\\imhye\\anaconda3\\envs\\ml_hyelin\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\imhye\\anaconda3\\envs\\ml_hyelin\\lib\\site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\imhye\\anaconda3\\envs\\ml_hyelin\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\imhye\\anaconda3\\envs\\ml_hyelin\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\imhye\\anaconda3\\envs\\ml_hyelin\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\imhye\\anaconda3\\envs\\ml_hyelin\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\imhye\\anaconda3\\envs\\ml_hyelin\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\imhye\\anaconda3\\envs\\ml_hyelin\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.3 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.16.3-cp310-none-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\imhye\\anaconda3\\envs\\ml_hyelin\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
      "   ---------------------------------------- 0.0/227.4 kB ? eta -:--:--\n",
      "   ---------------------------- ----------- 163.8/227.4 kB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  225.3/227.4 kB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 227.4/227.4 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading pydantic-2.6.3-py3-none-any.whl (395 kB)\n",
      "   ---------------------------------------- 0.0/395.2 kB ? eta -:--:--\n",
      "   ------------------------ --------------- 245.8/395.2 kB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  389.1/395.2 kB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 395.2/395.2 kB 3.1 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.16.3-cp310-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/1.9 MB 5.8 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.3/1.9 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.5/1.9 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.6/1.9 MB 3.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.7/1.9 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.8/1.9 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.9/1.9 MB 2.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.0/1.9 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.2/1.9 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.3/1.9 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.5/1.9 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.6/1.9 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.8/1.9 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 2.7 MB/s eta 0:00:00\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: pydantic-core, distro, annotated-types, pydantic, openai\n",
      "Successfully installed annotated-types-0.6.0 distro-1.9.0 openai-1.13.3 pydantic-2.6.3 pydantic-core-2.16.3\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ac3032-7aef-4c39-a3a8-e8e794f808bf",
   "metadata": {},
   "source": [
    "## 환경변수 준비\n",
    "- python-dotenv를 설치 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82a107f7-6c3a-4e48-9d40-46fb98789945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512f3a31-b741-4e4b-aac2-5737f61407a7",
   "metadata": {},
   "source": [
    "## .env 파일 저장\n",
    "- .env 파일 생성 후, OpenAI Key값을 아래와 같이 저장한다.\n",
    "```\n",
    "OPENAI_API_KEY = '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'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4101300b-e9fb-448a-99eb-c6b39c1ec9f0",
   "metadata": {},
   "source": [
    "## 저장한 값 불러오기\n",
    "- OPENAI_API_KEY를 불러오고 싶다면 다음 코드를 사용한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc2e56c7-a46f-4059-9b73-541d903d7034",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'OPENAI_API_KEY'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m env_file \u001b[38;5;241m=\u001b[39m dotenv\u001b[38;5;241m.\u001b[39mfind_dotenv()\n\u001b[0;32m      4\u001b[0m dotenv\u001b[38;5;241m.\u001b[39mload_dotenv(env_file)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOPENAI_API_KEY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ml_hyelin\\lib\\os.py:680\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    677\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodekey(key)]\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;66;03m# raise KeyError with the original key value\u001b[39;00m\n\u001b[1;32m--> 680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodevalue(value)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'OPENAI_API_KEY'"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "import os \n",
    "env_file = dotenv.find_dotenv()\n",
    "dotenv.load_dotenv(env_file)\n",
    "\n",
    "print(os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575c6546-aa98-4a8f-8f97-abcefcd15270",
   "metadata": {},
   "source": [
    "## 프롬프트 준비\n",
    "- 여러줄에 걸친 문자열 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32c8494d-772f-4afc-a668-845cc9788596",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "다음 이야기를 써주세요\n",
    "기타를 좋아하지만 컴맹인 여고생이 어떤 계기로 록밴드에 가입하고, 낯선 인간관계를 통해 활동하게 되는 이야기\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a6d687b-98ac-4c83-abdc-737c6436603c",
   "metadata": {},
   "source": [
    "- 각 매개변수에 대한 설명은 https://platform.openai.com/docs/api-reference/chat/create 링크 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfe9c84b-b769-4697-b1f7-520786efeeee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'남동생은 지금 사용자와 대화를 나누고 있습니다. 어떤 도움이 필요하세요?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    # api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    api_key = \"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\"\n",
    ")\n",
    "    \n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"이 채팅은 좋습니다. 남동생과 대하를 하겠습니다. \"},\n",
    "    {\"role\": \"user\", \"content\": \"안녕\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"남동생은 현재 컴퓨터를 하고 있습니다.\"},\n",
    "    {\"role\": \"user\", \"content\": \"너 지금 뭐하고 있어?\"}\n",
    "  ], \n",
    "   temperature=0\n",
    ")\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d6115c-21b8-4ec4-b909-b184409e2ae8",
   "metadata": {},
   "source": [
    "## 이미지 생성\n",
    "- 텍스트에서 이미지 생성을 하는 예제는 다음과 같다.\n",
    "- image generation 생성 및 매개변수에 대한 공식 문서는 다음과 같다.\n",
    "  + 참고 : https://platform.openai.com/docs/guides/images/introduction?context=node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4723d0ed-515f-4093-9214-29bd2fbbc0e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m----> 2\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# This is the default and can be omitted\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOPENAI_API_KEY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mimages\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m      8\u001b[0m   model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdall-e-3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m   prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcat dancing on car\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m   n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     15\u001b[0m image_url \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39murl\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ml_hyelin\\lib\\site-packages\\openai\\_client.py:98\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[1;34m(self, api_key, organization, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m     96\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m     )\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "response = client.images.generate(\n",
    "  model=\"dall-e-3\",\n",
    "  prompt=\"cat dancing on car\",\n",
    "  size=\"1024x1024\",\n",
    "  quality=\"standard\",\n",
    "  n=1,\n",
    ")\n",
    "\n",
    "image_url = response.data[0].url\n",
    "image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc467ff-2064-4c6e-8207-040a2eb10112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
